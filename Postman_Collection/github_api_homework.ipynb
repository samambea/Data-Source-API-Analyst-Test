{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AUTHENTICATION, FILE SAVING AND LOGGING"
      ],
      "metadata": {
        "id": "hJC37K5Q02WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logging configuration\n",
        "\n",
        "import logging\n",
        "import time\n",
        "import requests\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "log_directory = '/content/logs'\n",
        "if not os.path.exists(log_directory):\n",
        "    os.makedirs(log_directory)\n",
        "\n",
        "log_file_path = os.path.join(log_directory, 'github_api_session.log')\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "file_handler = logging.FileHandler(log_file_path)\n",
        "file_handler.setLevel(logging.DEBUG)\n",
        "\n",
        "console_handler = logging.StreamHandler()\n",
        "console_handler.setLevel(logging.INFO)\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "file_handler.setFormatter(formatter)\n",
        "console_handler.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(file_handler)\n",
        "logger.addHandler(console_handler)\n",
        "\n",
        "logger.propagate = False"
      ],
      "metadata": {
        "id": "yKBb1GlH3vkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE18E2db5DHc",
        "outputId": "0d8ee5ad-68b2-40ca-f6ab-6d584112c4b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GitHub Personal Access Token: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-11 02:22:49,718 - INFO - GitHub PAT and headers initialized.\n"
          ]
        }
      ],
      "source": [
        "# get github PAT securely w/getpass\n",
        "\n",
        "import getpass\n",
        "\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub Personal Access Token: ')\n",
        "headers = {\n",
        "    'Authorization': f'token {GITHUB_TOKEN}',\n",
        "    'Accept': 'application/vnd.github.v3+json'\n",
        "}\n",
        "\n",
        "logger.info(\"GitHub PAT and headers initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saves extracted data in a JSON file\n",
        "# files can be found in the 'Files' section of Colab\n",
        "\n",
        "import json\n",
        "\n",
        "def saveToJSON(data, filename):\n",
        "  try:\n",
        "    with open(filename, 'w') as f:\n",
        "      json.dump(data, f, indent=4)\n",
        "      logger.info(f\"Data successfully saved to {filename}\")\n",
        "  except IOError as e:\n",
        "        logger.error(f\"Failed to save data to {filename}: {e}\")"
      ],
      "metadata": {
        "id": "a31s_F_Aueye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLIENT NEEDS - EXTRACTION FUNCTIONS"
      ],
      "metadata": {
        "id": "PtD7tc_x1dN8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8ee7163"
      },
      "source": [
        "# search public repos\n",
        "# standard is 5 commits per page, 1 page extracted\n",
        "\n",
        "def searchRepos(query, per_page=5, page=1):\n",
        "    logger.info(f\"Searching repositories for query: '{query}', page: {page}, per_page: {per_page}\")\n",
        "    url = 'https://api.github.com/search/repositories'\n",
        "    params = {'q': query, 'per_page': per_page, 'page': page}\n",
        "    response = safeRequest(url, headers=headers, params=params)\n",
        "    return response.json()\n",
        "    logger.debug(f\"Search repos response (first 200 chars): {str(data)[:200]}...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9516a022"
      },
      "source": [
        "# list commits for a repo\n",
        "# standard is 5 commits per page, 1 page extracted\n",
        "\n",
        "def listCommits(owner, repo, per_page=5, page=1):\n",
        "    logger.info(f\"Listing commits for {owner}/{repo}, page: {page}, per_page: {per_page}\")\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}/commits'\n",
        "    params = {'per_page': per_page, 'page': page}\n",
        "    response = safeRequest(url, headers=headers, params=params)\n",
        "    return response.json()\n",
        "    logger.debug(f\"List commits response (first 200 chars): {str(data)[:200]}...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eca0d9c8"
      },
      "source": [
        "# get contents for a repo\n",
        "\n",
        "def getContents(owner, repo, path='', params=None):\n",
        "    logger.info(f\"Getting contents for {owner}/{repo} at path: {path}\")\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}/contents/{path}'\n",
        "    response = safeRequest(url, headers=headers, params=params)\n",
        "    return response.json()\n",
        "    logger.debug(f\"Get contents response (first 200 chars): {str(data)[:200]}...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ba63004"
      },
      "source": [
        "# pagination example\n",
        "\n",
        "def getAllCommits(owner, repo, max_pages=2):\n",
        "    logger.info(f\"Fetching all commits for {owner}/{repo} up to {max_pages} pages.\")\n",
        "    allCommits = []\n",
        "    for page in range(1, max_pages + 1):\n",
        "        commits = listCommits(owner, repo, per_page=100, page=page)\n",
        "        if not commits:\n",
        "            logger.info(f\"No more commits found or empty response for page {page}.\")\n",
        "            break\n",
        "        if 'message' in commits and commits.get('documentation_url'):\n",
        "            logger.warning(f\"API returned an error message for commits on page {page}: {commits['message']}\")\n",
        "            break\n",
        "        allCommits.extend(commits)\n",
        "        logger.info(f\"Added {len(commits)} commits from page {page}. Total commits so far: {len(allCommits)}\")\n",
        "    logger.info(f\"Finished fetching commits for {owner}/{repo}. Total: {len(allCommits)}\")\n",
        "    return allCommits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ERROR HANDLING"
      ],
      "metadata": {
        "id": "6q7t_a1g1oMf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4222fda1"
      },
      "source": [
        "# function safe request - error handling, including rate limit exceptions\n",
        "\n",
        "import time\n",
        "\n",
        "def safeRequest(url, headers, params=None):\n",
        "    logger.debug(f\"Attempting request to: {url} with params: {params}\")\n",
        "    try:\n",
        "        while True:\n",
        "            response = requests.get(url, headers=headers, params=params)\n",
        "            if response.status_code == 403 and 'X-RateLimit-Remaining' in response.headers and response.headers['X-RateLimit-Remaining'] == '0':\n",
        "                reset_time = int(response.headers['X-RateLimit-Reset'])\n",
        "                sleep_time = max(reset_time - time.time(), 0)\n",
        "                logger.warning(f'Rate limit reached. Sleeping for {sleep_time:.2f} seconds until {time.ctime(reset_time)}.')\n",
        "                time.sleep(sleep_time)\n",
        "            elif response.status_code != 200:\n",
        "                logger.error(f\"API Error: {response.status_code} - {response.text} for URL: {url}\")\n",
        "                response.raise_for_status()\n",
        "            else:\n",
        "                logger.info(f\"Successful request to {url}. Status: {response.status_code}\")\n",
        "                return response\n",
        "    except requests.exceptions.RequestException as e:\n",
        "      logger.error(f\"Request failed: {e} for URL: {url}\")\n",
        "      raise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING"
      ],
      "metadata": {
        "id": "MHzm-_XK1vRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"Starting API tests...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44JqUFWE9xtv",
        "outputId": "59a640ea-047f-4857-c41b-df3b0d8cebce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-11 02:22:49,782 - INFO - Starting API tests...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 1a - searchRepos - search about data science\n",
        "\n",
        "def test_searchRepos_success():\n",
        "    logger.info(\"Running test: searchRepos_success\")\n",
        "    try:\n",
        "        query = \"data science\"\n",
        "        repos = searchRepos(query)\n",
        "        assert repos is not None, \"searchRepos returned None\"\n",
        "        assert 'items' in repos, \"searchRepos response missing 'items' key\"\n",
        "        assert len(repos['items']) > 0, f\"searchRepos for '{query}' returned no items\"\n",
        "        saveToJSON(repos, f'{query.replace(\" \", \"_\")}_repos_test.json')\n",
        "        logger.info(\"Test 'searchRepos_success' passed.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Test 'searchRepos_success' failed: {e}\")\n",
        "\n",
        "# test 1b - searchRepos - search w/ no results\n",
        "\n",
        "def test_searchRepos_noResults():\n",
        "    logger.info(\"Running test: searchRepos_noResults\")\n",
        "    try:\n",
        "        query = \"thereisnotarepositorynamedlikethis\"\n",
        "        repos = searchRepos(query, per_page=1, page=1)\n",
        "        assert repos is not None, \"searchRepos returned None for no results query\"\n",
        "        assert 'items' in repos, \"searchRepos response missing 'items' key for no results query\"\n",
        "        assert len(repos['items']) == 0, f\"searchRepos for '{query}' returned items when none expected\"\n",
        "        logger.info(\"Test 'searchRepos_noResults' passed.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Test 'searchRepos_noResults' failed: {e}\")"
      ],
      "metadata": {
        "id": "p8zfdfZB3JnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 2a - listCommits - list Spoon-Knife's commits\n",
        "\n",
        "def test_listCommits_success():\n",
        "    logger.info(\"Running test: listCommits_success\")\n",
        "    try:\n",
        "        owner = \"octocat\"\n",
        "        repo = \"Spoon-Knife\"\n",
        "        commits = listCommits(owner, repo)\n",
        "        assert commits is not None, \"listCommits returned None\"\n",
        "        assert isinstance(commits, list), \"listCommits response is not a list\"\n",
        "        assert len(commits) > 0, f\"listCommits for {owner}/{repo} returned no commits\"\n",
        "        assert 'sha' in commits[0] and 'commit' in commits[0], \"Commit object missing expected keys\"\n",
        "        saveToJSON(commits, f'{owner}_{repo}_commits_test.json')\n",
        "        logger.info(\"Test 'list_commits_success' passed.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Test 'list_commits_success' failed: {e}\")\n",
        "\n",
        "\n",
        "# test 2b - listCommits - try to list non existing repo\n",
        "\n",
        "def test_listCommits_nonExistentRepo():\n",
        "    logger.info(\"Running test: listCommits_nonExistentRepo\")\n",
        "    try:\n",
        "        owner = \"nonexistentuser12345\"\n",
        "        repo = \"nonexistentrepo67890\"\n",
        "        commits = listCommits(owner, repo)\n",
        "        assert 'message' in commits and commits['message'] == 'Not Found', \"Expected 'Not Found' message for non-existent repo\"\n",
        "        logger.info(\"Test 'listCommits_nonExistentRepo' passed (handled 404).\")\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        if e.response.status_code == 404:\n",
        "            logger.info(\"Test 'listCommits_nonExistentRepo' passed (404 HTTPError caught).\")\n",
        "        else:\n",
        "            logger.error(f\"Test 'listCommits_nonExistentRepo' failed with unexpected HTTPError: {e}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Test 'listCommits_nonExistentRepo' failed unexpectedly: {e}\")"
      ],
      "metadata": {
        "id": "8OLXjpBy3M1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 3a - getContents - get cssBasics's README.md (my repo)\n",
        "\n",
        "def test_getContents_success():\n",
        "    logger.info(\"Running test: getContents_success\")\n",
        "    try:\n",
        "        owner = \"samambea\"\n",
        "        repo = \"cssBasics\"\n",
        "        contents = getContents(owner, repo, path='README.md')\n",
        "        assert contents is not None, \"getContents returned None\"\n",
        "        assert 'name' in contents and contents['name'] == 'README.md', \"Contents missing 'name' or incorrect\"\n",
        "        assert 'type' in contents and contents['type'] == 'file', \"Contents not of type 'file'\"\n",
        "        saveToJSON(contents, f'{owner}_{repo}_README_contents_test.json')\n",
        "        logger.info(\"Test 'get_contents_success' passed.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Test 'get_contents_success' failed: {e}\")\n",
        "\n",
        "# test 3b - getContents - get cssBasics's css folder (my repo)\n",
        "\n",
        "def test_getContents_directory():\n",
        "    logger.info(\"Running test: getContents_directory\")\n",
        "    try:\n",
        "        owner = \"samambea\"\n",
        "        repo = \"cssBasics\"\n",
        "        contents = getContents(owner, repo, path='projWeb/css')\n",
        "        assert contents is not None, \"getContents returned None for directory\"\n",
        "        assert isinstance(contents, list), \"Contents of directory not a list\"\n",
        "        assert len(contents) > 0, \"Directory contents list is empty\"\n",
        "        assert 'type' in contents[0] and contents[0]['type'] == 'file', \"Expected files in directory\"\n",
        "        saveToJSON(contents, f'{owner}_{repo}_css_dir_contents_test.json')\n",
        "        logger.info(\"Test 'getContents_directory' passed.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Test 'getContents_directory' failed: {e}\")\n",
        "\n",
        "# test 3b - getContents - try to get cssBasics's non existent path (my repo)\n",
        "\n",
        "def test_getContents_nonExistentPath():\n",
        "    logger.info(\"Running test: getContents_nonExistentPath\")\n",
        "    try:\n",
        "        owner = \"samambea\"\n",
        "        repo = \"cssBasics\"\n",
        "        path = \"thisfiledoesn'texist\"\n",
        "        contents = getContents(owner, repo, path=path)\n",
        "        assert 'message' in contents and contents['message'] == 'Not Found', \"Expected 'Not Found' message for non-existent path\"\n",
        "        logger.info(\"Test 'getContents_nonExistentPath' passed (handled 404).\")\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        if e.response.status_code == 404:\n",
        "            logger.info(\"Test 'getContents_nonExistentPath' passed (404 HTTPError caught).\")\n",
        "        else:\n",
        "            logger.error(f\"Test 'getContents_nonExistentPath' failed with unexpected HTTPError: {e}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Test 'getContents_nonExistentPath' failed unexpectedly: {e}\")\n"
      ],
      "metadata": {
        "id": "ZOGpZ9B_3PEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e160016"
      },
      "source": [
        "# test 4 - getAllCommits - pagination test\n",
        "\n",
        "def test_getAllCommits_pagination():\n",
        "    logger.info(\"Running test: getAllCommits_pagination\")\n",
        "    try:\n",
        "        owner = \"octocat\"\n",
        "        repo = \"Spoon-Knife\"\n",
        "        commits_page1 = getAllCommits(owner, repo, max_pages=1)\n",
        "        assert commits_page1 is not None, \"getAllCommits returned None for 1 page\"\n",
        "        assert len(commits_page1) > 0, \"getAllCommits returned no commits for 1 page\"\n",
        "        commits_page2 = getAllCommits(owner, repo, max_pages=2)\n",
        "        assert commits_page2 is not None, \"getAllCommits returned None for 2 pages\"\n",
        "        assert len(commits_page2) >= len(commits_page1), \"getAllCommits with 2 pages returned fewer commits than 1 page\"\n",
        "        saveToJSON(commits_page2, f'{owner}_{repo}_allCommits_test.json')\n",
        "        logger.info(\"Test 'getAllCommits_pagination' passed.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Test 'getAllCommits_pagination' failed: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all_tests():\n",
        "    test_searchRepos_success()\n",
        "    test_searchRepos_noResults()\n",
        "    test_listCommits_success()\n",
        "    test_listCommits_nonExistentRepo()\n",
        "    test_getContents_success()\n",
        "    test_getContents_directory()\n",
        "    test_getContents_nonExistentPath()\n",
        "    test_getAllCommits_pagination()"
      ],
      "metadata": {
        "id": "uFgkvSYRGFuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_all_tests()\n",
        "logger.info(\"API tests completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sOzo031Y96ZV",
        "outputId": "51371d57-a653-43b2-f29d-3f53de0c3039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-11 02:22:49,839 - INFO - Running test: searchRepos_success\n",
            "2025-07-11 02:22:49,841 - INFO - Searching repositories for query: 'data science', page: 1, per_page: 5\n",
            "2025-07-11 02:22:50,303 - INFO - Successful request to https://api.github.com/search/repositories. Status: 200\n",
            "2025-07-11 02:22:50,307 - INFO - Data successfully saved to data_science_repos_test.json\n",
            "2025-07-11 02:22:50,309 - INFO - Test 'searchRepos_success' passed.\n",
            "2025-07-11 02:22:50,310 - INFO - Running test: searchRepos_noResults\n",
            "2025-07-11 02:22:50,312 - INFO - Searching repositories for query: 'thereisnotarepositorynamedlikethis', page: 1, per_page: 1\n",
            "2025-07-11 02:22:50,571 - INFO - Successful request to https://api.github.com/search/repositories. Status: 200\n",
            "2025-07-11 02:22:50,573 - INFO - Test 'searchRepos_noResults' passed.\n",
            "2025-07-11 02:22:50,574 - INFO - Running test: listCommits_success\n",
            "2025-07-11 02:22:50,575 - INFO - Listing commits for octocat/Spoon-Knife, page: 1, per_page: 5\n",
            "2025-07-11 02:22:50,780 - INFO - Successful request to https://api.github.com/repos/octocat/Spoon-Knife/commits. Status: 200\n",
            "2025-07-11 02:22:50,784 - INFO - Data successfully saved to octocat_Spoon-Knife_commits_test.json\n",
            "2025-07-11 02:22:50,785 - INFO - Test 'list_commits_success' passed.\n",
            "2025-07-11 02:22:50,786 - INFO - Running test: listCommits_nonExistentRepo\n",
            "2025-07-11 02:22:50,787 - INFO - Listing commits for nonexistentuser12345/nonexistentrepo67890, page: 1, per_page: 5\n",
            "2025-07-11 02:22:50,929 - ERROR - API Error: 404 - {\"message\":\"Not Found\",\"documentation_url\":\"https://docs.github.com/rest/commits/commits#list-commits\",\"status\":\"404\"} for URL: https://api.github.com/repos/nonexistentuser12345/nonexistentrepo67890/commits\n",
            "2025-07-11 02:22:50,931 - ERROR - Request failed: 404 Client Error: Not Found for url: https://api.github.com/repos/nonexistentuser12345/nonexistentrepo67890/commits?per_page=5&page=1 for URL: https://api.github.com/repos/nonexistentuser12345/nonexistentrepo67890/commits\n",
            "2025-07-11 02:22:50,932 - INFO - Test 'listCommits_nonExistentRepo' passed (404 HTTPError caught).\n",
            "2025-07-11 02:22:50,934 - INFO - Running test: getContents_success\n",
            "2025-07-11 02:22:50,936 - INFO - Getting contents for samambea/cssBasics at path: README.md\n",
            "2025-07-11 02:22:51,159 - INFO - Successful request to https://api.github.com/repos/samambea/cssBasics/contents/README.md. Status: 200\n",
            "2025-07-11 02:22:51,161 - INFO - Data successfully saved to samambea_cssBasics_README_contents_test.json\n",
            "2025-07-11 02:22:51,164 - INFO - Test 'get_contents_success' passed.\n",
            "2025-07-11 02:22:51,166 - INFO - Running test: getContents_directory\n",
            "2025-07-11 02:22:51,167 - INFO - Getting contents for samambea/cssBasics at path: projWeb/css\n",
            "2025-07-11 02:22:51,378 - INFO - Successful request to https://api.github.com/repos/samambea/cssBasics/contents/projWeb/css. Status: 200\n",
            "2025-07-11 02:22:51,380 - INFO - Data successfully saved to samambea_cssBasics_css_dir_contents_test.json\n",
            "2025-07-11 02:22:51,382 - INFO - Test 'getContents_directory' passed.\n",
            "2025-07-11 02:22:51,384 - INFO - Running test: getContents_nonExistentPath\n",
            "2025-07-11 02:22:51,386 - INFO - Getting contents for samambea/cssBasics at path: thisfiledoesn'texist\n",
            "2025-07-11 02:22:51,597 - ERROR - API Error: 404 - {\"message\":\"Not Found\",\"documentation_url\":\"https://docs.github.com/rest/repos/contents#get-repository-content\",\"status\":\"404\"} for URL: https://api.github.com/repos/samambea/cssBasics/contents/thisfiledoesn'texist\n",
            "2025-07-11 02:22:51,598 - ERROR - Request failed: 404 Client Error: Not Found for url: https://api.github.com/repos/samambea/cssBasics/contents/thisfiledoesn'texist for URL: https://api.github.com/repos/samambea/cssBasics/contents/thisfiledoesn'texist\n",
            "2025-07-11 02:22:51,600 - INFO - Test 'getContents_nonExistentPath' passed (404 HTTPError caught).\n",
            "2025-07-11 02:22:51,601 - INFO - Running test: getAllCommits_pagination\n",
            "2025-07-11 02:22:51,602 - INFO - Fetching all commits for octocat/Spoon-Knife up to 1 pages.\n",
            "2025-07-11 02:22:51,603 - INFO - Listing commits for octocat/Spoon-Knife, page: 1, per_page: 100\n",
            "2025-07-11 02:22:51,787 - INFO - Successful request to https://api.github.com/repos/octocat/Spoon-Knife/commits. Status: 200\n",
            "2025-07-11 02:22:51,790 - INFO - Added 3 commits from page 1. Total commits so far: 3\n",
            "2025-07-11 02:22:51,791 - INFO - Finished fetching commits for octocat/Spoon-Knife. Total: 3\n",
            "2025-07-11 02:22:51,792 - INFO - Fetching all commits for octocat/Spoon-Knife up to 2 pages.\n",
            "2025-07-11 02:22:51,793 - INFO - Listing commits for octocat/Spoon-Knife, page: 1, per_page: 100\n",
            "2025-07-11 02:22:52,041 - INFO - Successful request to https://api.github.com/repos/octocat/Spoon-Knife/commits. Status: 200\n",
            "2025-07-11 02:22:52,048 - INFO - Added 3 commits from page 1. Total commits so far: 3\n",
            "2025-07-11 02:22:52,049 - INFO - Listing commits for octocat/Spoon-Knife, page: 2, per_page: 100\n",
            "2025-07-11 02:22:52,245 - INFO - Successful request to https://api.github.com/repos/octocat/Spoon-Knife/commits. Status: 200\n",
            "2025-07-11 02:22:52,251 - INFO - No more commits found or empty response for page 2.\n",
            "2025-07-11 02:22:52,252 - INFO - Finished fetching commits for octocat/Spoon-Knife. Total: 3\n",
            "2025-07-11 02:22:52,266 - INFO - Data successfully saved to octocat_Spoon-Knife_allCommits_test.json\n",
            "2025-07-11 02:22:52,268 - INFO - Test 'getAllCommits_pagination' passed.\n",
            "2025-07-11 02:22:52,277 - INFO - API tests completed.\n"
          ]
        }
      ]
    }
  ]
}